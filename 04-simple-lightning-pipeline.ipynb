{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ef16fa-efdf-4aab-909e-752c20352bcb",
   "metadata": {},
   "source": [
    "# Pytorch Lightning Training Pipeline\n",
    "\n",
    "![lightning-logo](https://upload.wikimedia.org/wikipedia/commons/e/e6/Lightning_Logo_v2.png)\n",
    "\n",
    "In this section, we will create a deep learning model using [PyTorch Lightning](https://www.pytorchlightning.ai/index.html), which is a tool that helps us train neural networks more easily. It is a lightweight and flexible Python library that simplifies the process of training and organizing deep learning models using PyTorch. It provides a high-level interface and a set of abstractions that make it easier to structure, debug, and scale complex deep learning projects.\n",
    "\n",
    "For this project, we will develop the popular [ResNet](https://arxiv.org/abs/1512.03385) variants: ResNet-18 and ResNet-50. Our goal is to compare these models and determine which one is most effective for solving the challenge at hand. We learned about the [Food101-tiny](https://www.kaggle.com/datasets/msarmi9/food101tiny) dataset in the previous section, and now we will develop a simple dataset parser that can read and apply enhancements to the data.\n",
    "\n",
    "Configurations:\n",
    "- Model: ResNet-18, ResNet-50\n",
    "- Dataset: Food101-tiny\n",
    "- Input Size: 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfcadee6-ab05-410e-95f7-93aa15918a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fiftyone 0.21.0 requires starlette<0.27,>=0.24.0, but you have starlette 0.22.0 which is incompatible.\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade -q lightning torchmetrics fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fbbb3d-b486-4084-85ea-41c004cc786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.abspath('')\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data/food-101-tiny')\n",
    "\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DATA_PATH = os.path.join(DATA_DIR, 'valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10a25c-8ce7-470c-a1a6-4f0a08c3b227",
   "metadata": {},
   "source": [
    "## Dataset Pipeline\n",
    "\n",
    "To build the dataset pipeline, we must understand about the dataset itself. Every researchers, developers, or organizations have different style of how to store and read the data. It is important to understand the datatypes, data structures, and storing methods.\n",
    "\n",
    "In this example, the data has been organized such that the images are inside a subfolder that represent the class names. For each splits, there will be 10 subfolders that containes the images for the classes.\n",
    "\n",
    "```\n",
    "data/\n",
    "----food-101-tiny/\n",
    "    ----train/\n",
    "        ----apple_pie/\n",
    "            bibimbap/\n",
    "            cannoli/\n",
    "            ...\n",
    "            ...\n",
    "            tiramisu/\n",
    "    ----valid/\n",
    "```\n",
    "\n",
    "There are 2 ways to load the dataset, the easy way is to use `torchvision.datasets.ImageFolder` or the hard way to search for the images and read it manually or simply just reimplement the `ImageFolder`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942a801-1578-47cf-b4ab-d7ae064158e7",
   "metadata": {},
   "source": [
    "### Augmentation Policy\n",
    "\n",
    "For training, we're using the following augmentation steps:\n",
    "- random rotation\n",
    "- random flipping\n",
    "- center crop\n",
    "- normalize the data\n",
    "\n",
    "For validation, we only need to resize and normalize the dataset.\n",
    "It's important to only apply the augmentation policy to the training split and just resizing operation for the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd84efbf-a51d-483b-8243-0dc233557630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "RGB_MEAN = [0.51442681, 0.43435301, 0.33421855]\n",
    "RGB_STD = [0.24099932, 0.246478, 0.23652802]\n",
    "INPUT_SIZE = (384, 384)\n",
    "\n",
    "TRAIN_TRANSFORMATION = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.CenterCrop(INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=RGB_MEAN, std=RGB_STD)\n",
    "])\n",
    "\n",
    "VAL_TRANSFORMATION = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.CenterCrop(INPUT_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=RGB_MEAN, std=RGB_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb0a1a-078b-4356-899c-cda3360a1aa6",
   "metadata": {},
   "source": [
    "### Dataset Parser\n",
    "\n",
    "Build a custom dataset parser to read a structured folder from before. This function will read the images from the subsequent folders from the *root_dir*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8082daaf-76f8-4601-8cd6-cb34b7929e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "\n",
    "class ImageFolderDataset(Dataset):\n",
    "    \"\"\"Strutured Image Folder Dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : str\n",
    "        Path to image root directory\n",
    "    transform : Optional[torchvision.transforms.Compose], optional\n",
    "        Data augmentation pipeline, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: str, stage: Optional[str] = None, transform: Optional[torchvision.transforms.Compose] = None):\n",
    "        if stage is not None:\n",
    "            self.root_dir = os.path.join(root_dir, stage)\n",
    "        else:\n",
    "            self.root_dir = root_dir\n",
    "        if not os.path.exists(root_dir):\n",
    "            raise RuntimeError(f'Path to dataset is not valid')\n",
    "        self.labels_name = os.listdir(self.root_dir)\n",
    "        self.labels_name.sort()\n",
    "        self.list_images =  glob.glob(f'{self.root_dir}/**/*.jpg')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Get number of images.\"\"\"\n",
    "        return len(self.list_images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Get sample for the current idx.\"\"\"\n",
    "        img_path = self.list_images[idx]\n",
    "\n",
    "        # NOTE: cv2 read image as BGR.\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Convert class name to label 0-10\n",
    "        # NOTE: root_path/class_name/image_file.jpg\n",
    "        class_name = img_path.split('/')[-2]\n",
    "        label_index = self.labels_name.index(class_name)\n",
    "        label_index = [label_index]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # If no transformations, convert to C,H,W\n",
    "        # Normalize to [0,1]\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = np.transpose(image, (1, 2, 0))\n",
    "            image = torch.from_numpy()\n",
    "            image /= 255.0\n",
    "\n",
    "        return image, torch.tensor(label_index, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a644f-70c1-4d91-899d-70fb0aa3ae4b",
   "metadata": {},
   "source": [
    "#### Test and Validate\n",
    "\n",
    "To ensure the function works properly, we must test and validate the parser will return some expected values.\n",
    "\n",
    "Note: **Don't forget to cleanup the variables** since it will consume the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabf3e5a-fe91-49b3-af4d-a888c3f6c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolderDataset(root_dir=DATA_DIR, stage = 'train', transform=TRAIN_TRANSFORMATION)\n",
    "image, label = train_dataset[10]\n",
    "\n",
    "assert len(train_dataset) == 1500\n",
    "assert isinstance(image, torch.Tensor)\n",
    "assert isinstance(label, torch.Tensor)\n",
    "\n",
    "val_dataset = ImageFolderDataset(root_dir=VAL_DATA_PATH, transform=VAL_TRANSFORMATION)\n",
    "image, label = train_dataset[10]\n",
    "\n",
    "assert len(val_dataset) == 500\n",
    "assert isinstance(image, torch.Tensor)\n",
    "assert isinstance(label, torch.Tensor)\n",
    "\n",
    "# Cleanup to reduce memory\n",
    "train_dataset = None\n",
    "val_dataset = None\n",
    "image, label = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56cdd93-d58b-4084-8d61-7dd867af2311",
   "metadata": {},
   "source": [
    "### LightningDataModule Pipeline\n",
    "\n",
    "To use the dataset with PyTorch Lightning, we have to build the custom datamodule that is required by the pipeline to load and parse the data using [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3555cd-9190-402b-9e6a-1eb75b61937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "class Food101LitDatamodule(LightningDataModule):\n",
    "    \"\"\"LightningDataModule for Food101 Data Pipeline.\n",
    "\n",
    "    Read the docs:\n",
    "        https://lightning.ai/docs/pytorch/latest/data/datamodule.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str, optional\n",
    "        FiftyOne dataset directory, by default 'data/'\n",
    "    input_size : List[int], optional\n",
    "        Input model size, by default [600, 500]\n",
    "    batch_size : int, optional\n",
    "        Number of training batch size, by default 64\n",
    "    num_workers : int, optional\n",
    "        Number of worksers to process data, by default 0\n",
    "    pin_memory : bool, optional\n",
    "        Enable memory pinning, by default False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = 'data/',\n",
    "        input_size: Tuple[int, int] = (600, 500),\n",
    "        batch_size: int = 64,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        \"\"\"Get number of classes.\"\"\"\n",
    "        return 10\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Load the data with specified stage.\"\"\"\n",
    "        if stage in ['train', 'fit', None] and self.data_train is None:\n",
    "            self.data_train = ImageFolderDataset(\n",
    "                root_dir=self.hparams.data_dir, stage='train', transform=TRAIN_TRANSFORMATION)\n",
    "            if len(self.data_train) == 0:\n",
    "                raise ValueError('Train dataset is empty.')\n",
    "        if stage in ['validation', 'test', 'fit', None]:\n",
    "            if self.data_val is None:\n",
    "                self.data_val = ImageFolderDataset(\n",
    "                    root_dir=self.hparams.data_dir, stage='valid', transform=VAL_TRANSFORMATION)\n",
    "                if len(self.data_val) == 0:\n",
    "                    raise ValueError('Validation dataset is empty.')\n",
    "            if self.data_test is None:\n",
    "                self.data_test = ImageFolderDataset(\n",
    "                    root_dir=self.hparams.data_dir, stage='valid', transform=VAL_TRANSFORMATION)\n",
    "                if len(self.data_test) == 0:\n",
    "                    raise ValueError('Test dataset is empty.')\n",
    "        if stage == 'predict':\n",
    "            if self.data_test is None:\n",
    "                self.data_predict = ImageFolderDataset(\n",
    "                    root_dir=self.hparams.data_dir, transform=VAL_TRANSFORMATION)\n",
    "                if len(self.data_predict) == 0:\n",
    "                    raise ValueError('Predict dataset is empty.')\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Get train dataloader.\"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Get validation dataloader.\"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        \"\"\"Get test dataloader.\"\"\"\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cb722-ae98-420f-8523-54a495abaae1",
   "metadata": {},
   "source": [
    "#### Test and Validate\n",
    "\n",
    "To ensure the function works properly, we must test and validate the parser will return some expected values.\n",
    "\n",
    "Note: **Don't forget to cleanup the variables** since it will consume the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fabf2d6-3fb3-4293-a137-c2b3e2cbd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = Food101LitDatamodule(data_dir=DATA_DIR, batch_size=4)\n",
    "\n",
    "assert not dm.data_train and not dm.data_val and not dm.data_test\n",
    "\n",
    "dm.setup()\n",
    "assert dm.data_train and dm.data_val and dm.data_test\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n",
    "test_dataloader = dm.test_dataloader()\n",
    "assert train_dataloader and val_dataloader and test_dataloader\n",
    "\n",
    "assert len(dm.data_train) + len(dm.data_val) + len(dm.data_test) == 2500\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "x, y = batch\n",
    "assert len(x) == 4\n",
    "assert len(y) == 4\n",
    "assert x.dtype == torch.float32\n",
    "assert y.dtype == torch.int64\n",
    "\n",
    "# Cleanup\n",
    "dm = None\n",
    "batch = None\n",
    "train_dataloader, val_dataloader, test_dataloader = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc176668-f2d5-4881-be6d-0e088e532a33",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The most important part of any ResNet architecture is its basic block. It contains a stacking of a few convolutional, batch normalization, and ReLU activation layers which are common for all the ResNet models.\n",
    "\n",
    "![resnet-model](https://debuggercafe.com/wp-content/uploads/2022/08/resnet18-basic-blocks-1.png)\n",
    "\n",
    "Define a basic ResNet18 Building Block. Each block consists of two convolutional layers and supports skip connections.\n",
    "\n",
    "![resnet-block](https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ace113-6efd-48f0-8aec-189473b6cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"ResNet Basic Block.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels\n",
    "    out_channels : int\n",
    "        Number of output channels\n",
    "    stride : int, optional\n",
    "        Convolution stride size, by default 1\n",
    "    identity_downsample : Optional[torch.nn.Module], optional\n",
    "        Downsampling layer, by default None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                in_channels: int,\n",
    "                out_channels: int,\n",
    "                stride: int = 1,\n",
    "                identity_downsample: Optional[torch.nn.Module] = None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,\n",
    "                              out_channels, \n",
    "                              kernel_size = 3,\n",
    "                              stride = stride,\n",
    "                              padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels,\n",
    "                              out_channels,\n",
    "                              kernel_size = 3,\n",
    "                              stride = 1,\n",
    "                              padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.identity_downsample = identity_downsample\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply forward computation.\"\"\"\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Apply an operation to the identity output.\n",
    "        # Useful to reduce the layer size and match from conv2 output\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8019122-2a77-40d3-a054-641b0a663ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \"\"\"Construct ResNet-18 Model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_channels : int\n",
    "        Number of input channels\n",
    "    num_classes : int\n",
    "        Number of class outputs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels,\n",
    "                               64, kernel_size = 7,\n",
    "                              stride = 2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3,\n",
    "                                   stride = 2,\n",
    "                                   padding = 1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(64, 64, stride = 1)\n",
    "        self.layer2 = self._make_layer(64, 128, stride = 2)\n",
    "        self.layer3 = self._make_layer(128, 256, stride = 2)\n",
    "        self.layer4 = self._make_layer(256, 512, stride = 2)\n",
    "        \n",
    "        # Last layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def identity_downsample(self, in_channels: int, out_channels: int) -> nn.Module:\n",
    "        \"\"\"Downsampling block to reduce the feature sizes.\"\"\"\n",
    "        return nn.Sequential(\n",
    "             nn.Conv2d(in_channels, \n",
    "                       out_channels, \n",
    "                       kernel_size = 3, \n",
    "                       stride = 2,\n",
    "                       padding = 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_channels: int, out_channels: int, stride: int) -> nn.Module:\n",
    "        \"\"\"Create sequential basic block.\"\"\"\n",
    "        identity_downsample = None\n",
    "\n",
    "        # Add downsampling function\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "                    BasicBlock(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride),\n",
    "                    BasicBlock(out_channels, out_channels)\n",
    "                    )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd06d43-8bef-4033-8894-c415de1d4733",
   "metadata": {},
   "source": [
    "#### Test and Validate\n",
    "\n",
    "To ensure the function works properly, we must test and validate the parser will return some expected values.\n",
    "\n",
    "Note: **Don't forget to cleanup the variables** since it will consume the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a38bc8b3-045b-473d-b2b8-835aee3a3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(3, 10)\n",
    "\n",
    "input = torch.rand(1, 3, 256, 256)\n",
    "output = model(input)\n",
    "\n",
    "assert output.shape == torch.Size([1, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c49880-720f-4249-bcb0-89f7ace35057",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "\n",
    "In PyTorch Lightning, **LightningModule** is a key component that serves as the core building block for defining and organizing deep learning models. It is an abstract class provided by the PyTorch Lightning library that extends PyTorch's nn.Module.\n",
    "\n",
    "A LightningModule **encapsulates all the necessary components of a deep learning model**, including the model architecture, forward pass logic, loss functions, and optimization methods. It provides a standardized interface and a set of predefined hooks to handle various aspects of the training process, such as data loading, training/validation loops, and testing.\n",
    "\n",
    "For more details, read the full documentation [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b9bc64-8e46-406c-b341-29c72294e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics as tm\n",
    "from lightning import LightningModule\n",
    "\n",
    "\n",
    "class ClassificationLightningModule(LightningModule):\n",
    "    \"\"\"Model training pipeline for Food101 classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : torch.nn.Module\n",
    "        The model module or configuration\n",
    "    num_classes : int, optional\n",
    "        Number of output classes, by default 10\n",
    "    lr : float, optional\n",
    "        Optimizer learning rate, by default 0.00001\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: torch.nn.Module,\n",
    "        num_classes: int = 10,\n",
    "        lr: float = 0.00001\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.net = net\n",
    "\n",
    "        # loss function\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # metric objects for calculating and averaging accuracy across batches\n",
    "        self.train_acc = tm.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "        self.val_metrics = tm.MetricCollection({\n",
    "            'acc': tm.Accuracy(task='multiclass', num_classes=num_classes),\n",
    "            'prec': tm.Precision(task='multiclass', num_classes=num_classes),\n",
    "            'rec': tm.Recall(task='multiclass', num_classes=num_classes),\n",
    "            'auroc': tm.AUROC(task='multiclass', num_classes=num_classes),\n",
    "            'f1': tm.F1Score(task='multiclass', num_classes=num_classes),\n",
    "        })  # type: ignore\n",
    "\n",
    "        self.test_metrics = self.val_metrics.clone()\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        self.train_acc.reset()\n",
    "        self.val_metrics.reset()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.net(x)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        # by default lightning executes validation step sanity checks before training starts,\n",
    "        # so it's worth to make sure validation metrics don't store results from these checks\n",
    "        self.reset_metrics()\n",
    "\n",
    "    def model_step(self, batch: Any):\n",
    "        images, targets = batch\n",
    "        targets = targets.squeeze().long() # convert to 1D\n",
    "        logits = self.forward(images)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        preds = F.softmax(logits, dim=1)\n",
    "        return loss, preds, targets\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        acc = self.train_acc(preds, targets)\n",
    "        self.log('train/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train/acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # return loss or backpropagation will fail\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        self.reset_metrics()\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        metrics = self.val_metrics(preds, targets)\n",
    "        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val/acc', metrics['acc'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val/prec', metrics['prec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/rec', metrics['rec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/auroc', metrics['auroc'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/f1', metrics['f1'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int):\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        # update and log metrics\n",
    "        metrics = self.test_metrics(preds, targets)\n",
    "        self.log('test/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test/acc', metrics['acc'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('test/prec', metrics['prec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('test/rec', metrics['rec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('test/auroc', metrics['auroc'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('test/f1', metrics['f1'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure the optimizer and scheduler to use.\n",
    "\n",
    "        Examples:\n",
    "            https://lightning.ai/docs/pytorch/latest/common/lightning_module.html#configure-optimizers\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "        )\n",
    "\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e21988-9373-418b-82e6-5763560f8e93",
   "metadata": {},
   "source": [
    "#### Test and Validate\n",
    "\n",
    "To ensure the function works properly, we must test and validate the parser will return some expected values.\n",
    "\n",
    "Note: **Don't forget to cleanup the variables** since it will consume the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e9fdbfa-9386-41dc-969e-3b360eeb0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:615: UserWarning: Checkpoint directory /home/haritsahm/Documents/Getting Started/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | net          | ResNet18           | 12.6 M\n",
      "1 | criterion    | CrossEntropyLoss   | 0     \n",
      "2 | train_acc    | MulticlassAccuracy | 0     \n",
      "3 | val_metrics  | MetricCollection   | 0     \n",
      "4 | test_metrics | MetricCollection   | 0     \n",
      "----------------------------------------------------\n",
      "12.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.251    Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409e0243ccec47aebe650e3618753ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.trainer import Trainer\n",
    "\n",
    "# Construct the model\n",
    "model = ResNet18(3, 10)\n",
    "\n",
    "# Construct training pipeline\n",
    "lit_model = ClassificationLightningModule(\n",
    "    net = model,\n",
    "    num_classes = 10,\n",
    "    lr = 0.001,\n",
    ")\n",
    "\n",
    "# Construct the datamodule\n",
    "datamodule = Food101LitDatamodule(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=4,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"fast_dev_run\": True,\n",
    "    \"max_epochs\": 1,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**training_config)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)\n",
    "\n",
    "trainer = None\n",
    "datamodule = None\n",
    "lit_model = None\n",
    "model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315950e-ad25-4f53-829d-3ad6ca146253",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "\n",
    "The **Trainer** function in PyTorch Lightning is a key component that provides a high-level interface for training and managing the training process of deep learning models. It acts as a central orchestrator, handling crucial aspects such as training loops, validation loops, logging, checkpointing, and distributed training.\n",
    "\n",
    "Additionally, the **Trainer** function integrates with other PyTorch Lightning components, such as LightningModule and DataLoader, streamlining the training pipeline. It handles the training and validation loops, automatically applies the specified callbacks, and provides options for logging and visualization of training progress and metrics.\n",
    "\n",
    "Please read the full [documentation](https://lightning.ai/docs/pytorch/stable/common/trainer.html) to understand the full functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cb3fcd8-fcc4-4748-abfe-991ae6cadb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/utilities/parsing.py:196: UserWarning: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/haritsahm/Documents/Getting Started/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | net          | ResNet18           | 12.6 M\n",
      "1 | criterion    | CrossEntropyLoss   | 0     \n",
      "2 | train_acc    | MulticlassAccuracy | 0     \n",
      "3 | val_metrics  | MetricCollection   | 0     \n",
      "4 | test_metrics | MetricCollection   | 0     \n",
      "----------------------------------------------------\n",
      "12.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.251    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed74a26d237548cdb99949d1ef29c985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "[rank: 0] Received SIGTERM: 15\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.trainer import Trainer\n",
    "\n",
    "# Global Variables\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Construct the model\n",
    "model = ResNet18(3, NUM_CLASSES)\n",
    "\n",
    "# Construct training pipeline\n",
    "lit_model = ClassificationLightningModule(\n",
    "    net = model,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    lr = LEARNING_RATE,\n",
    ")\n",
    "\n",
    "# Construct the datamodule\n",
    "datamodule = Food101LitDatamodule(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "training_config = {\n",
    "    \"accelerator\": 'auto',\n",
    "    \"devices\": 'auto',\n",
    "    \"precision\": 32,\n",
    "    \"max_epochs\": 100,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**training_config)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65be24c-03ab-4373-afe7-c5a09bbad84a",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Note that this is just an example, you have to improve the performance by applying different augmentations, models, hyperparameter tuning, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da1b4bd3-f966-4d09-bf80-ffb21d1c32af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b970ee9aac34c76a53b4663c08290f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6320000290870667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0502019077539444     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6320000290870667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.3324941396713257     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/prec         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6320000290870667     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/rec          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6320000290870667     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6320000290870667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test/auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0502019077539444    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test/f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6320000290870667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.3324941396713257    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/prec        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6320000290870667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/rec         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6320000290870667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 1.3324941396713257,\n",
       "  'test/acc': 0.6320000290870667,\n",
       "  'test/prec': 0.6320000290870667,\n",
       "  'test/rec': 0.6320000290870667,\n",
       "  'test/auroc': 0.0502019077539444,\n",
       "  'test/f1': 0.6320000290870667}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable randomness, dropout, etc...\n",
    "lit_model.eval()\n",
    "\n",
    "trainer.test(model=lit_model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87944f0-2332-4e3a-9669-d9e36d4f4a84",
   "metadata": {},
   "source": [
    "This notebook shows you a simple use of PyTorch Lightning to develop classification models. In the next section we will integrate a helpful functionalites to our pipeline in order to help us understand better about the training process and the results using an experiment tracking.\n",
    "\n",
    "PyTorch Lightning has a lot of practical [hands-on](https://lightning.ai/docs/pytorch/stable/tutorials.html) to develop deep learning models, you should spend more time on reading and practicing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
