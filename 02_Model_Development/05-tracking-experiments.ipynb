{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fea730f-7f8d-441e-863e-144dab2252c4",
   "metadata": {},
   "source": [
    "# Experiment Tracking using Weight & Biases (W&B)\n",
    "\n",
    "![wnb-logo](https://raw.githubusercontent.com/wandb/wandb/020f30e567f6d168bc18eaa668ff063d28163fd7/docs/README_images/logo-light.svg)\n",
    "\n",
    "**Weights and Biases (W&B)** is a platform that provides tools for tracking and visualizing machine learning experiments. It aims to enhance the workflow of researchers and practitioners by offering features to log, analyze, and compare various aspects of their experiments.\n",
    "\n",
    "**W&B** allows you to easily log and monitor different parameters during training, such as model performance metrics, hyperparameters, and intermediate outputs. It provides interactive visualizations and dashboards to track the progress of your models over time.\n",
    "\n",
    "To simplify the notebook, the codes from the previous notebook will be moved to `src/` folder and we only need to call it from here. This section only shows how to use `wandb` with `lightning`and add other functionality to help understand the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f5b817-d137-4cd5-afd1-5a85324c400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.9.4)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (65.5.1)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[K     |████████████████████████████████| 184 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e11490626c6700a3b33124c83d27e338f822b665b16ea14f76cb11b29ce35ba7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9lea8ta2/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built pathtools\n",
      "Installing collected packages: smmap, gitdb, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, appdirs, wandb\n",
      "Successfully installed GitPython-3.1.31 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.24.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d96d53ee-39aa-4e33-9ff8-2ff2872695d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(''))\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'data/food-101-tiny')\n",
    "\n",
    "TRAIN_DATA_PATH = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DATA_PATH = os.path.join(DATA_DIR, 'valid')\n",
    "SIMPLE_MODEL_CHECKPOINT = os.path.join(ROOT_DIR, 'pretrained/simple-lightning-epoch100/resnet18_epoch99.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db8534-93a8-4fb0-bd36-133ae0810e7c",
   "metadata": {},
   "source": [
    "## Initialize a Project in W&B\n",
    "\n",
    "[Login](https://wandb.ai/site) to your W&B account and create a new project called `learning-food101-tiny`.\n",
    "\n",
    "Copy the `API Key` for that project and login through the Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a0bf93-39dc-4674-b3ef-7f352ab4f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mharitsahm\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import wandb\n",
    "\n",
    "API_KEY = getpass.getpass()\n",
    "wandb.login(key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b8faa-0f0f-4fbe-9bb2-c2106095a03d",
   "metadata": {},
   "source": [
    "## Track Training Logs with W&B\n",
    "\n",
    "To use **W&B** with PyTorch Lightning, you can simply add the `W&B Logger` as a callback in your PyTorch Lightning `Trainer` configuration. This allows you to automatically log metrics, hyperparameters, and other metadata to your W&B project. With W&B and PyTorch Lightning, you can monitor your training progress in real-time through the W&B dashboard. It provides interactive visualizations, charts, and tables to help you analyze and compare experiments effortlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "134d85d6-597e-498d-89a3-b349451e04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | net          | ResNet18           | 12.6 M\n",
      "1 | criterion    | CrossEntropyLoss   | 0     \n",
      "2 | train_acc    | MulticlassAccuracy | 0     \n",
      "3 | val_metrics  | MetricCollection   | 0     \n",
      "4 | test_metrics | MetricCollection   | 0     \n",
      "----------------------------------------------------\n",
      "12.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.251    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74bb282f50844b2a44115dfefed34a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0155c8ed06c54627bca415444bd18550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>train/acc</td><td>▁▃▅█▁▄█▅▇▇</td></tr><tr><td>train/loss</td><td>█▅▃▂▅▂▁▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>val/acc</td><td>▁▅▅▆▆▄▆█▅▆</td></tr><tr><td>val/auroc</td><td>▁▅▇▇▇█▇█▅▄</td></tr><tr><td>val/f1</td><td>▁▅▅▆▆▅▆█▅▆</td></tr><tr><td>val/loss</td><td>█▄▂▂▄▃▂▁▄▃</td></tr><tr><td>val/prec</td><td>▁▆▅▇▆▇▇█▄▆</td></tr><tr><td>val/rec</td><td>▁▅▅▆▆▄▆█▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train/acc</td><td>0.23931</td></tr><tr><td>train/loss</td><td>0.99751</td></tr><tr><td>trainer/global_step</td><td>3749</td></tr><tr><td>val/acc</td><td>0.0658</td></tr><tr><td>val/auroc</td><td>0.0068</td></tr><tr><td>val/f1</td><td>0.0758</td></tr><tr><td>val/loss</td><td>1.2469</td></tr><tr><td>val/prec</td><td>0.09733</td></tr><tr><td>val/rec</td><td>0.0658</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-capybara-1</strong> at: <a href='https://wandb.ai/haritsahm/learning-food101-tiny/runs/1kne51xz' target=\"_blank\">https://wandb.ai/haritsahm/learning-food101-tiny/runs/1kne51xz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_084116-1kne51xz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.trainer import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from src import models, dataset\n",
    "from src.models import BasicBlock, ResNet18, ClassificationLightningModule\n",
    "\n",
    "# Global Variables\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Load from checkpoint training pipeline\n",
    "lit_model = ClassificationLightningModule.load_from_checkpoint(SIMPLE_MODEL_CHECKPOINT)\n",
    "\n",
    "# Construct the datamodule\n",
    "datamodule = dataset.Food101LitDatamodule(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# NOTE: Rename the project to your use case.\n",
    "wandb_logger = WandbLogger(project=\"learning-food101-tiny\")\n",
    "\n",
    "training_config = {\n",
    "    \"accelerator\": 'auto',\n",
    "    \"devices\": 'auto',\n",
    "    \"precision\": 32,\n",
    "    \"max_epochs\": 10,\n",
    "    \"logger\": wandb_logger,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**training_config)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)\n",
    "\n",
    "# Sync current run with cloud.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d40fb-e462-45a6-b496-45463b3c93a4",
   "metadata": {},
   "source": [
    "While the training is on going, you can monitor the progress from W&B dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69addb9a-e559-4dce-a31b-50efcefef8fc",
   "metadata": {},
   "source": [
    "## Save Checkpoint to W&B\n",
    "\n",
    "There are several ways to log `model`/`checkpoints` to W&B as described in the [WandbLogger](https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.loggers.wandb.html)\n",
    "- Using `watch` to Log gradients, parameters and model topology\n",
    "- Use `Callbacks` and log only the last or best model\n",
    "\n",
    "For this experiment we're going to use `Callbacks` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "557c5d93-b91c-47d7-b85e-3db49c928bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | net          | ResNet18           | 12.6 M\n",
      "1 | criterion    | CrossEntropyLoss   | 0     \n",
      "2 | train_acc    | MulticlassAccuracy | 0     \n",
      "3 | val_metrics  | MetricCollection   | 0     \n",
      "4 | test_metrics | MetricCollection   | 0     \n",
      "----------------------------------------------------\n",
      "12.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.251    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ade0d9519044e18a7c825d0d4c4bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# NOTE: Rename the project to your use case.\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"learning-food101-tiny\",\n",
    "    log_model=True,\n",
    ")\n",
    "\n",
    "# Model Checkpoint Callback\n",
    "## Full arguments are available from https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.callbacks.ModelCheckpoint.html#modelcheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val/acc\", mode=\"max\")\n",
    "\n",
    "# Define the Trainer metrics\n",
    "## Full arguments are available from https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api\n",
    "training_config = {\n",
    "    \"accelerator\": 'auto',\n",
    "    \"devices\": 'auto',\n",
    "    \"precision\": 32,\n",
    "    \"max_epochs\": 10,\n",
    "    \"logger\": wandb_logger,\n",
    "    \"callbacks\": [checkpoint_callback],\n",
    "}\n",
    "\n",
    "trainer = Trainer(**training_config)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)\n",
    "\n",
    "# Sync current run with cloud.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1fdda02-41e1-4222-b6d5-01e67440df56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>train/acc</td><td>▁▆▂▂█▂▄▆▆▂</td></tr><tr><td>train/loss</td><td>█▄▇▆▂▆▄▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>val/acc</td><td>▆▅▁▁▆▇▄▆▃█</td></tr><tr><td>val/auroc</td><td>█▆▃█▁█▃▆▆█</td></tr><tr><td>val/f1</td><td>▆▅▁▂▆▇▅▆▃█</td></tr><tr><td>val/loss</td><td>▃▇█▄▃▁▂▃▆▂</td></tr><tr><td>val/prec</td><td>▆▆▁▁██▆▃▅▇</td></tr><tr><td>val/rec</td><td>▆▅▁▁▆▇▄▆▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train/acc</td><td>0.24078</td></tr><tr><td>train/loss</td><td>0.90191</td></tr><tr><td>trainer/global_step</td><td>3749</td></tr><tr><td>val/acc</td><td>0.0706</td></tr><tr><td>val/auroc</td><td>0.008</td></tr><tr><td>val/f1</td><td>0.07985</td></tr><tr><td>val/loss</td><td>1.10898</td></tr><tr><td>val/prec</td><td>0.1</td></tr><tr><td>val/rec</td><td>0.0706</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-dust-2</strong> at: <a href='https://wandb.ai/haritsahm/learning-food101-tiny/runs/39i1ct57' target=\"_blank\">https://wandb.ai/haritsahm/learning-food101-tiny/runs/39i1ct57</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_085623-39i1ct57/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sync current run with cloud.\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06030372-9293-4220-8c9c-5b6d54ab1e07",
   "metadata": {},
   "source": [
    "After the training finished, you should see the last and best checkpoints in the run artifact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b966d-cd96-431c-8f46-cfd555be976a",
   "metadata": {},
   "source": [
    "## Track and Visualize Image Predictions\n",
    "\n",
    "**Explainability is a crucial aspect**, especially when developing computer vision models, as it allows us to **understand and interpret the decisions made** by these models. By providing explanations, we gain insights into how and why a particular prediction was made, which helps build trust, detect biases, and debug the models. Explainability is particularly important in applications such as medical diagnosis, autonomous vehicles, and critical decision-making systems where the impact of a wrong prediction can be significant.\n",
    "\n",
    "One useful tool for explaining computer vision models is GradCAM (Gradient-weighted Class Activation Mapping), which is available in the [pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam) repository on GitHub. GradCAM helps in visualizing and interpreting the decisions made by a deep neural network, specifically in the context of image classification tasks.\n",
    "\n",
    "GradCAM **highlights the regions** of an input image that are **most influential in determining the model's prediction** for a specific class. It achieves this by computing the gradients of the target class score with respect to the feature maps in the final convolutional layer of the network. These gradients are then used to weigh the feature maps, producing a class activation map that visually represents the important regions of the image for the predicted class.\n",
    "\n",
    "![grad-cam](https://miro.medium.com/v2/resize:fit:720/format:webp/0*nE5_ZjRhOcslpvXI.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46f4e863-8d97-4b2e-ad4c-4fff6122aa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q grad-cam "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d25ef4-dc95-47b4-a35c-4c813a471ecb",
   "metadata": {},
   "source": [
    "### Adding GradCAM\n",
    "\n",
    "We're adding the `gradcam` in the evaluation step. Instead of constructing a new `LightningModule`, we're going to inherit from `ClassificationLightningModule` that we developed earlier to reuse the pipeline and only modify a certain part of it. Note that this function will add extra computation load and longer training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94be5b83-f2b1-47fa-94ec-5e47ed8b187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from typing import Any\n",
    "\n",
    "from src import dataset\n",
    "from src.models import ClassificationLightningModule\n",
    "from pytorch_grad_cam import EigenCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from wandb import wandb_run\n",
    "\n",
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = np.reciprocal(dataset.RGB_STD).tolist()),\n",
    "                                transforms.Normalize(mean = [-1 * item for item in dataset.RGB_MEAN],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "class AdvancedLightningModule(ClassificationLightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: torch.nn.Module,\n",
    "        num_classes: int = 10,\n",
    "        lr: float = 0.00001,\n",
    "    ):\n",
    "\n",
    "        super().__init__(net, num_classes, lr)\n",
    "\n",
    "        # Define GradCAM functions\n",
    "        target_layers = [net.layer4]\n",
    "        param = [p for p in net.parameters()]\n",
    "        GRAD_CAM = EigenCAM(net, target_layers, use_cuda=False)\n",
    "\n",
    "        self.grad_cam_targets = [ClassifierOutputTarget(10)]\n",
    "        self.grad_cam_profiler = EigenCAM(net, target_layers)\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> None:\n",
    "        images, targets = batch\n",
    "        loss, preds, targets = self.model_step(batch)\n",
    "\n",
    "        vis_images = []\n",
    "        grayscale_cams = self.grad_cam_profiler(input_tensor=images, targets=self.grad_cam_targets)\n",
    "\n",
    "        \n",
    "        for idx in range(len(images)):\n",
    "            if idx > 15: # Limit to 16 grids\n",
    "                break\n",
    "            gt = targets[idx].detach().cpu()\n",
    "            pd = preds[idx].detach().cpu()\n",
    "            pd = torch.argmax(pd)\n",
    "            norm_img = invTrans(images[idx])\n",
    "            norm_img = torch.permute(norm_img, (1, 2, 0)) # C,H,W -> H,W,C\n",
    "            cam_image = show_cam_on_image(norm_img.detach().cpu().numpy(), grayscale_cams[idx], use_rgb=True)\n",
    "            wandb_image = wandb.Image(cam_image, caption=f\"Target: {gt.item()} - Pred: {pd.item()}\")\n",
    "            vis_images.append(wandb_image)\n",
    "\n",
    "        # Log the data to W&B\n",
    "        for logger in self.loggers:\n",
    "            if isinstance(logger.experiment, wandb_run.Run):\n",
    "                logger.experiment.log({\"val_images\": vis_images})\n",
    "\n",
    "        # update and log metrics\n",
    "        metrics = self.val_metrics(preds, targets)\n",
    "        self.log('val/loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val/acc', metrics['acc'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val/prec', metrics['prec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/rec', metrics['rec'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/auroc', metrics['auroc'], on_step=False, on_epoch=True, prog_bar=False)\n",
    "        self.log('val/f1', metrics['f1'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a12021-81b8-4dd0-9508-7d44ac0d9070",
   "metadata": {},
   "source": [
    "### Retrain Using Addition Logging\n",
    "\n",
    "With the new pipeline, we're going to retrain the model. After it finish, you can check the logged samples in W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f82a67b-8d1b-4fcd-a0ae-bec8d252d881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.8/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory ./learning-food101-tiny/r38wk5j6/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type               | Params\n",
      "----------------------------------------------------\n",
      "0 | net          | ResNet18           | 12.6 M\n",
      "1 | criterion    | CrossEntropyLoss   | 0     \n",
      "2 | train_acc    | MulticlassAccuracy | 0     \n",
      "3 | val_metrics  | MetricCollection   | 0     \n",
      "4 | test_metrics | MetricCollection   | 0     \n",
      "----------------------------------------------------\n",
      "12.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.6 M    Total params\n",
      "50.251    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b048916ed14a699087e188fc7331aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.trainer import Trainer\n",
    "from src.models import BasicBlock, ResNet18, ClassificationLightningModule\n",
    "from src import dataset\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "# Global Variables\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Construct the model\n",
    "model = ResNet18(3, 10)\n",
    "\n",
    "# Construct training pipeline\n",
    "lit_model = AdvancedLightningModule(\n",
    "    net = model,\n",
    "    num_classes = NUM_CLASSES,\n",
    "    lr = LEARNING_RATE,\n",
    ")\n",
    "\n",
    "# Construct the datamodule\n",
    "datamodule = dataset.Food101LitDatamodule(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# NOTE: Rename the project to your use case.\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"learning-food101-tiny\",\n",
    "    log_model=True,\n",
    ")\n",
    "\n",
    "# Define the Trainer metrics\n",
    "## Full arguments are available from https://lightning.ai/docs/pytorch/stable/common/trainer.html#trainer-class-api\n",
    "training_config = {\n",
    "    \"accelerator\": 'auto',\n",
    "    \"devices\": 'auto',\n",
    "    \"max_epochs\": 10,\n",
    "    \"logger\": wandb_logger,\n",
    "}\n",
    "\n",
    "trainer = Trainer(**training_config)\n",
    "trainer.fit(model=lit_model, datamodule=datamodule)\n",
    "\n",
    "# Sync current run with cloud.\n",
    "wandb.finish()\n",
    "\n",
    "trainer = None\n",
    "datamodule = None\n",
    "lit_model = None\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ff77ea-d598-4884-b67b-5b6549c2472e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁</td></tr><tr><td>train/acc</td><td>▁█</td></tr><tr><td>train/loss</td><td>█▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/acc</td><td>▁█</td></tr><tr><td>val/auroc</td><td>█▁</td></tr><tr><td>val/f1</td><td>▁█</td></tr><tr><td>val/loss</td><td>▁█</td></tr><tr><td>val/prec</td><td>▁█</td></tr><tr><td>val/rec</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train/acc</td><td>0.172</td></tr><tr><td>train/loss</td><td>2.33883</td></tr><tr><td>trainer/global_step</td><td>374</td></tr><tr><td>val/acc</td><td>0.2</td></tr><tr><td>val/auroc</td><td>0.004</td></tr><tr><td>val/f1</td><td>0.2</td></tr><tr><td>val/loss</td><td>3.0033</td></tr><tr><td>val/prec</td><td>0.2</td></tr><tr><td>val/rec</td><td>0.2</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-vortex-4</strong> at: <a href='https://wandb.ai/haritsahm/learning-food101-tiny/runs/r38wk5j6' target=\"_blank\">https://wandb.ai/haritsahm/learning-food101-tiny/runs/r38wk5j6</a><br/>Synced 5 W&B file(s), 508 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230525_095247-r38wk5j6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sync current run with cloud.\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
